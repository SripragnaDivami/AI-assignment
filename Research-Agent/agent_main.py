# Generated by Copilot
# agent_main.py
import asyncio
import logging
from pydantic_ai import Agent, RunContext
from models import ResearchResult
from tools import mock_search, safe_eval_expression
from log_config import configure_logfire
import logfire
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging + logfire
configure_logfire()
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# Get Google API key from environment
google_api_key = os.getenv("GOOGLE_API_KEY")
if not google_api_key:
    raise ValueError("GOOGLE_API_KEY not found in environment variables")

# Set the API key in environment for pydantic-ai to use
os.environ["GOOGLE_API_KEY"] = google_api_key

# --- Create Agent ---
agent = Agent(
    model='google-gla:gemini-2.5-flash',  # Using correct Gemini model
    system_prompt='''You are a helpful research assistant with access to Wikipedia search and a calculator.

When answering questions:
1. Use the search tool to look up factual information when needed
2. If Wikipedia doesn't have information, use your general knowledge to provide a helpful answer
3. Be conversational and helpful - don't say you can't answer just because Wikipedia doesn't have an article
4. For books, movies, or topics not in Wikipedia, use your knowledge to provide useful information
5. Use the calculator for math problems
6. Always provide complete, informative answers based on your knowledge and available tools'''
)

# --- Register Tools ---
@agent.tool
async def search(ctx: RunContext, query: str) -> str:
    """Search Wikipedia for factual information. Use this for well-known topics, people, places, or historical events."""
    try:
        logfire.info("tool.search.start", query=query)
        results = await mock_search(query)
        if results and results[0].get("snippet") and results[0]["snippet"] not in ["No results found", "No description available"]:
            # Format the Wikipedia results
            formatted = "\n\n".join([
                f"**{r['title']}**\n{r['snippet']}\nSource: {r['url']}"
                for r in results if r.get("snippet")
            ])
            logfire.info("tool.search.success", query=query, count=len(results))
            return formatted
        else:
            logfire.warning("tool.search.not_found", query=query)
            return f"No Wikipedia article found for '{query}'"
    except Exception as e:
        logfire.error("tool.search.error", query=query, error=str(e))
        return f"Wikipedia search error: {str(e)}"

@agent.tool
def calculate(ctx: RunContext, expression: str) -> float:
    """Evaluate mathematical expressions safely. Supports basic math operations and functions like sin, cos, sqrt, etc."""
    try:
        logfire.info("tool.calculate.start", expression=expression)
        result = safe_eval_expression(expression)
        logfire.info("tool.calculate.success", expression=expression, result=result)
        return result
    except Exception as e:
        logfire.error("tool.calculate.error", expression=expression, error=str(e))
        raise

# --- High-level research function ---
async def research_topic(query: str, message_history: list = None) -> tuple[ResearchResult, list]:
    """
    Research a topic and maintain conversation history.
    Returns (ResearchResult, updated_message_history)
    """
    max_retries = 3
    for attempt in range(max_retries):
        try:
            logfire.info("research.start", query=query, attempt=attempt+1)
            result = await agent.run(query, message_history=message_history)
            logfire.info("research.success", query=query)
            return (
                ResearchResult(query=query, answer=str(result.output)),
                result.all_messages()
            )
        except Exception as e:
            error_msg = str(e)
            if "503" in error_msg or "overloaded" in error_msg.lower():
                if attempt < max_retries - 1:
                    wait_time = 3 * (2 ** attempt)  # 3s, 6s, 12s
                    logger.warning(f"Model overloaded, waiting {wait_time}s before retry {attempt+2}/{max_retries}...")
                    logfire.warning("research.retry", query=query, attempt=attempt+1, wait_time=wait_time)
                    await asyncio.sleep(wait_time)
                    continue
            
            logfire.error("research.error", query=query, error=error_msg)
            return (
                ResearchResult(query=query, answer=f"Error: The service is temporarily unavailable. Please try again in a moment."),
                message_history or []
            )

# --- Main ---
async def main():
    print("=== Research Agent ===")
    print("Enter your research topic (or 'exit' to quit):\n")
    
    message_history = []  # Initialize empty message history
    
    while True:
        topic = input("You: ").strip()
        
        if topic.lower() in ['exit', 'quit', 'bye']:
            print("Goodbye!")
            break
            
        if not topic:
            print("Please enter a valid topic.\n")
            continue
        
        # Get response with message history
        result, message_history = await research_topic(topic, message_history)
        print(f"Agent: {result.answer}")
        print()

if __name__ == "__main__":
    asyncio.run(main())
